{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TAGCN Reproducibility Challenge",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hungpai/ML4G-Project-3/blob/main/TAGCN_Reproducibility_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make sure to set runtime to GPU in colab."
      ],
      "metadata": {
        "id": "PTHTtnK-GXuR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyWj5JHQVG8E",
        "outputId": "70f61821-edda-4102-c809-3bd4ae4869cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 36.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 27.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 33.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (747 kB)\n",
            "\u001b[K     |████████████████████████████████| 747 kB 31.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 31.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 621 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581968 sha256=d347087761880c68220ca7af1499d8a7c427de217818bf889eb24983eb21c43b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-geometric-2.0.3 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "# Ensure that the right PyG is installed and compatible with the recent update of colab!\n",
        "import torch \n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "1 \n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "# set runtime to GPU in collab for fast computations!\n",
        "CUDA_version = torch.version.cuda\n",
        "#CUDA = \"cpu\"\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import TAGConv, GCNConv, ChebConv"
      ],
      "metadata": {
        "id": "J6LOsjQ1WNNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "NqSW69OjWUu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pubmed\n",
        "pubmed_dataset = Planetoid(root=\"data\", name=\"PubMed\", split=\"public\")\n",
        "\n",
        "# Citeseer\n",
        "citeseer_dataset = Planetoid(root=\"data\", name=\"CiteSeer\", split=\"public\")\n",
        "\n",
        "# Cora dataset\n",
        "cora_dataset = Planetoid(root=\"data\", name=\"Cora\", split=\"public\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zTFIicnWY4s",
        "outputId": "e54d92bd-0246-4bc4-8daa-767907d02c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset statistics"
      ],
      "metadata": {
        "id": "k9eReuO3Xy94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_statistics(dataset):\n",
        "  print('================')\n",
        "  print(f'Dataset: {dataset}')\n",
        "  print(f'Number of graphs: {len(dataset)}')\n",
        "  print(f'Number of features: {dataset.num_features}')\n",
        "  print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "  data = dataset[0]\n",
        "\n",
        "  print(data)\n",
        "  print('==============================================================')\n",
        "\n",
        "  print(f'Number of nodes: {data.num_nodes}')\n",
        "  print(f'Number of edges: {data.num_edges}')\n",
        "  print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "  print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "  print(f'Number of validation nodes: {data.val_mask.sum()}')\n",
        "  print(f'Number of test nodes: {data.test_mask.sum()}')\n",
        "  print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:f}')\n",
        "  print(f'Contains isolated nodes: {data.has_isolated_nodes()}')\n",
        "  print(f'Contains self-loops: {data.has_self_loops()}')\n",
        "  print(f'Is undirected: {data.is_undirected()}\\n')\n",
        "\n",
        "print_statistics(pubmed_dataset)\n",
        "print_statistics(citeseer_dataset)\n",
        "print_statistics(cora_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUNR6UfDXxUj",
        "outputId": "a91e547a-283a-4aea-96a0-e77749362bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================\n",
            "Dataset: PubMed()\n",
            "Number of graphs: 1\n",
            "Number of features: 500\n",
            "Number of classes: 3\n",
            "Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])\n",
            "==============================================================\n",
            "Number of nodes: 19717\n",
            "Number of edges: 88648\n",
            "Average node degree: 4.50\n",
            "Number of training nodes: 60\n",
            "Number of validation nodes: 500\n",
            "Number of test nodes: 1000\n",
            "Training node label rate: 0.003043\n",
            "Contains isolated nodes: False\n",
            "Contains self-loops: False\n",
            "Is undirected: True\n",
            "\n",
            "================\n",
            "Dataset: CiteSeer()\n",
            "Number of graphs: 1\n",
            "Number of features: 3703\n",
            "Number of classes: 6\n",
            "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n",
            "==============================================================\n",
            "Number of nodes: 3327\n",
            "Number of edges: 9104\n",
            "Average node degree: 2.74\n",
            "Number of training nodes: 120\n",
            "Number of validation nodes: 500\n",
            "Number of test nodes: 1000\n",
            "Training node label rate: 0.036069\n",
            "Contains isolated nodes: True\n",
            "Contains self-loops: False\n",
            "Is undirected: True\n",
            "\n",
            "================\n",
            "Dataset: Cora()\n",
            "Number of graphs: 1\n",
            "Number of features: 1433\n",
            "Number of classes: 7\n",
            "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
            "==============================================================\n",
            "Number of nodes: 2708\n",
            "Number of edges: 10556\n",
            "Average node degree: 3.90\n",
            "Number of training nodes: 140\n",
            "Number of validation nodes: 500\n",
            "Number of test nodes: 1000\n",
            "Training node label rate: 0.051699\n",
            "Contains isolated nodes: False\n",
            "Contains self-loops: False\n",
            "Is undirected: True\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models: TAGCN, GCN, ChebNet"
      ],
      "metadata": {
        "id": "mYMTC3rjZpXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TAGCNNet(nn.Module):\n",
        "  def __init__(self, num_features, num_classes, filter_number, filter_size):\n",
        "    super().__init__()\n",
        "    self.conv1 = TAGConv(num_features, filter_number, filter_size)\n",
        "    self.relu  = nn.ReLU()\n",
        "    self.dropout = nn.Dropout()\n",
        "    self.conv2 = TAGConv(filter_number, num_classes, filter_size)\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "  \n",
        "  def forward(self, x, edge_index, edge_attr):\n",
        "    x = self.conv1(x, edge_index, edge_attr)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.conv2(x, edge_index, edge_attr)\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "\n",
        "class GCNNet(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(num_features, 16, cached=True, normalize=True)\n",
        "        self.relu  = nn.ReLU()\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.conv2 = GCNConv(16, num_classes, cached=True, normalize=True)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        \n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        x = self.conv1(x, edge_index, edge_attr)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index, edge_attr)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "class ChebNet(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = ChebConv(num_features, 16, K=2)\n",
        "        self.relu  = nn.ReLU()\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.conv2 = ChebConv(16, num_classes, K=2)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        x = self.conv1(x, edge_index, edge_attr)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index, edge_attr)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "_ErzTNF8hPnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Structure"
      ],
      "metadata": {
        "id": "fie02gGWGN-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, loss_func, x, y, train_mask, edge_attr, edge_index):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(x, edge_index, edge_attr)\n",
        "    loss = loss_func(pred[train_mask], y[train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def test(model, data, x, y, edge_attr, edge_index):\n",
        "    model.eval()\n",
        "    logits, accs = model(x, edge_index, edge_attr), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        pred = logits[mask].argmax(1)\n",
        "        acc = (pred == y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "def training_loop(dataset, model=0, filter_number=16, filter_size=2, stats=True):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  if model == 0:\n",
        "    model = TAGCNNet(dataset.num_features, dataset.num_classes, filter_number, filter_size).to(device)\n",
        "  elif model ==1:\n",
        "    model = GCNNet(dataset.num_features, dataset.num_classes).to(device)\n",
        "  else:\n",
        "    model = ChebNet(dataset.num_features, dataset.num_classes).to(device)\n",
        "\n",
        "  data = dataset[0].to(device)\n",
        "\n",
        "  epochs= 200\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  file_name = s=f'{(str(dataset)[0:-2])}.pt'\n",
        "\n",
        "  # early stopping\n",
        "  counter = 0\n",
        "  best_val_acc = -float('inf')\n",
        "  patience = 45\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train(model, optimizer, loss_func, data.x, data.y, data.train_mask, data.edge_attr, data.edge_index)\n",
        "      train_acc, val_acc, tmp_test_acc = test(model, data, data.x, data.y, data.edge_attr, data.edge_index)\n",
        "\n",
        "      # stop mechanism\n",
        "      if val_acc > best_val_acc:\n",
        "        counter = 0\n",
        "        best_val_acc = val_acc\n",
        "        test_acc = tmp_test_acc\n",
        "        torch.save(model.state_dict(), file_name)\n",
        "      else:\n",
        "        counter += 1\n",
        "        if counter > patience:\n",
        "          if stats:\n",
        "            print(f\"Validation loss over the last {patience} epochs not improved, terminate training\\n\")\n",
        "          model.load_state_dict(torch.load(file_name))\n",
        "          break\n",
        "      \n",
        "      if epoch % 10 == 9 and stats:\n",
        "        print(f'Epoch: [{epoch+1}/{epochs}], Train: {train_acc:.4f}, Val: {best_val_acc:.4f}, Test: {test_acc:.4f}')\n",
        "    \n",
        "  model.load_state_dict(torch.load(file_name))\n",
        "  return model"
      ],
      "metadata": {
        "id": "WTa1m-AXhRW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training TAGCN models with different configuration"
      ],
      "metadata": {
        "id": "NtCYHRZ9iWsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = [pubmed_dataset, citeseer_dataset, cora_dataset]\n",
        "configs = [(1,16),(2,16),(3,16),(4,16),(2,8)] # (filter_size, filter_number)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "runs = 10\n",
        "\n",
        "for dataset in datasets:\n",
        "  for config in configs:\n",
        "    acc = 0\n",
        "    for run in range(runs):\n",
        "      filter_size, filter_number = config\n",
        "      model = training_loop(dataset, 0, filter_number, filter_size, False)\n",
        "      \n",
        "      data = dataset[0].to(device)\n",
        "      _, _, accuracy = test(model, data, data.x, data.y, data.edge_attr, data.edge_index)\n",
        "      acc += accuracy\n",
        "  \n",
        "    avg_acc = acc / runs\n",
        "    print(f\"dataset: {str(dataset):<12} filter_size:{filter_size} \\tfilter_number:{filter_number} \\taccuracy:{avg_acc*100:.2f}%\")\n",
        "  print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdi8aJDMPTIm",
        "outputId": "e4046e56-8240-495c-9901-a29828f142f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset: PubMed()     filter_size:1 \tfilter_number:16 \taccuracy:77.74%\n",
            "dataset: PubMed()     filter_size:2 \tfilter_number:16 \taccuracy:78.95%\n",
            "dataset: PubMed()     filter_size:3 \tfilter_number:16 \taccuracy:78.70%\n",
            "dataset: PubMed()     filter_size:4 \tfilter_number:16 \taccuracy:79.19%\n",
            "dataset: PubMed()     filter_size:2 \tfilter_number:8 \taccuracy:78.46%\n",
            "\n",
            "dataset: CiteSeer()   filter_size:1 \tfilter_number:16 \taccuracy:67.93%\n",
            "dataset: CiteSeer()   filter_size:2 \tfilter_number:16 \taccuracy:67.82%\n",
            "dataset: CiteSeer()   filter_size:3 \tfilter_number:16 \taccuracy:68.72%\n",
            "dataset: CiteSeer()   filter_size:4 \tfilter_number:16 \taccuracy:68.24%\n",
            "dataset: CiteSeer()   filter_size:2 \tfilter_number:8 \taccuracy:64.26%\n",
            "\n",
            "dataset: Cora()       filter_size:1 \tfilter_number:16 \taccuracy:78.15%\n",
            "dataset: Cora()       filter_size:2 \tfilter_number:16 \taccuracy:81.01%\n",
            "dataset: Cora()       filter_size:3 \tfilter_number:16 \taccuracy:80.70%\n",
            "dataset: Cora()       filter_size:4 \tfilter_number:16 \taccuracy:80.75%\n",
            "dataset: Cora()       filter_size:2 \tfilter_number:8 \taccuracy:79.80%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training GCN and ChebNet model"
      ],
      "metadata": {
        "id": "SwQSWNJXibpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [1,2] #1: GCN, 2: Chebnet\n",
        "for mod in models:\n",
        "  for dataset in datasets:\n",
        "    acc = 0\n",
        "    for run in range(runs):\n",
        "      model = training_loop(dataset, mod, stats=False)\n",
        "      \n",
        "      data = dataset[0].to(device)\n",
        "      _, _, accuracy = test(model, data, data.x, data.y, data.edge_attr, data.edge_index)\n",
        "      acc += accuracy\n",
        "    avg_acc = acc / runs\n",
        "    if mod == 1:\n",
        "      m = 'GCN'\n",
        "    else:\n",
        "      m = 'ChebNet'\n",
        "    print(f\"dataset: {str(dataset):<12} model:{m} \\taccuracy:{avg_acc*100:.2f}%\")\n",
        "  print('')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMlVEH87h4Vr",
        "outputId": "254c003d-a9d9-44b5-8042-0da6d15b2391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset: PubMed()     model:GCN \taccuracy:78.38%\n",
            "dataset: CiteSeer()   model:GCN \taccuracy:68.47%\n",
            "dataset: Cora()       model:GCN \taccuracy:80.41%\n",
            "\n",
            "dataset: PubMed()     model:ChebNet \taccuracy:77.85%\n",
            "dataset: CiteSeer()   model:ChebNet \taccuracy:63.26%\n",
            "dataset: Cora()       model:ChebNet \taccuracy:78.70%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}